# ğŸ“… Medical Assistant Chatbot â€” RAG-based Application

![Medical Chatbot Thumbnail](./assets/medicalAssistant.png)

> ğŸ¥ **Watch the full project walkthrough:** [YouTube Video](https://youtube.com/your-video-link)
>
> ğŸ—‚ï¸ **Architecture PDF:** [View Architecture](./assets/MedicalAssistant.pdf)

---

## ğŸ§  Project Overview

This application is a **Medical Domain Chatbot** built using **Retrieval-Augmented Generation (RAG)**. It allows users to upload their own medical documents (e.g., textbooks, reports), and the system intelligently answers queries by retrieving the most relevant content before generating a final response.

---

## ğŸ“ What is RAG?

**RAG (Retrieval-Augmented Generation)** enhances language models by supplying relevant external context from a knowledge base, preventing hallucinations and improving accuracy, especially for factual or specialized domains like **medicine**.

---

## ğŸ”„ Architecture

```
User Input
   â†“
Query Embedding â†’ Pinecone Vector DB â† Embedded Chunks â† Chunking â† PDF Loader
   â†“
Retrieved Docs
   â†“
     RAG Chain (Groq + LangChain)
   â†“
LLM-generated Answer
```

For a detailed view, refer to the **[MedicalAssistant.pdf](./assets/MedicalAssistant.pdf)**

---

## ğŸ“š Features

- Upload medical PDFs (notes, books, etc.)
- Auto-extracts text and splits into semantic chunks
- Embeds using Google/BGE embeddings
- Stores vectors in **Pinecone DB**
- Uses **Groq's LLaMA3-70B** via LangChain
- FastAPI backend with endpoints for file upload and Q\&A

---

## ğŸŒ Tech Stack

| Component  | Tech Used                  |
| ---------- | -------------------------- |
| LLM        | Groq API (LLaMA3-70B)      |
| Embeddings | Google Generative AI / BGE |
| Vector DB  | Pinecone                   |
| Framework  | LangChain                  |
| Backend    | FastAPI                    |
| Deployment | Render                     |

---

## ğŸ“š API Endpoints

```http
POST /upload_pdfs/
- Upload one or more PDF files

POST /ask/
- Ask a question
- Form field: `question`

GET /test
- Health check endpoint
```

---

## ğŸ“ Folder Structure

```
.
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ load_vectorstore.py
â”‚   â”‚   â”œâ”€â”€ llm.py
â”‚   â”‚   â”œâ”€â”€ query_handler.py
â”‚   â”‚   â””â”€â”€ pdf_handler.py
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ client/            # (Optional frontend)
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ thumbnail.png
â”‚   â””â”€â”€ architecture.pdf
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš¡ Quick Setup

```bash
# Clone the repo
$ git clone https://github.com/your-username/medical-rag-chatbot.git
$ cd medical-rag-chatbot/server

# Create virtual env
$ python -m venv venv
$ source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
$ pip install -r requirements.txt

# Set environment variables (.env)
GOOGLE_API_KEY=...
GROQ_API_KEY=...
PINECONE_API_KEY=...

# Run the server
$ uvicorn main:app --reload --port 8000
```

---

## ğŸŒ Deployment

- Hosted on [Render](https://render.com)
- Configure `start command` as:

  ```bash
  uvicorn main:app --host 0.0.0.0 --port 10000
  ```

- Install `python-multipart` for FastAPI form data support:

  ```bash
  pip install python-multipart
  ```

---

## ğŸŒŸ Credits

- Built by \[Your Name]
- Inspired by LangChain, Groq, Pinecone, and FastAPI ecosystems

---

## ğŸ‰ License

This project is licensed under the MIT License.
